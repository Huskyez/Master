{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4KB6d3U4XhPI"
   },
   "source": [
    "# Practical Machine Learning\n",
    "# Lab 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WG4LSTnnXhPJ"
   },
   "source": [
    "## k-Nearest Neighbor\n",
    "\n",
    "In this lab, we are going to classify handwritten digits from the MNIST database using k-NN and Naive Bayes. This dataset consists of 60000 training images and 10000 testing images. Each image is labeled with one of 10 classes (0-9 digit). The images are gray-scale and have 28 pixels high and wide. We are going to use a subset divided as follows:\n",
    "    \n",
    "    ‘train_images.npy’ is a matrix of 1000 x 784, containing 1000 training images, each row is an image (28 x 28 = 784).\n",
    "    ‘test_images.npy’ is a matrix of 500 x 784 containing 500 testing images.\n",
    "    ‘train_labels.npy’ and ‘test_labels.npy’ contains the ground-truth labels.\n",
    "\n",
    "![mnist_examples.png](attachment:mnist_examples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "zMsMvpZnXhPK"
   },
   "source": [
    "Download the images and the ground-truth labels from [here](url). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bL4SVxagXhPL"
   },
   "outputs": [],
   "source": [
    "# import matplotlib and numpy libraries\n",
    "# you should run it only once\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 456,
     "status": "error",
     "timestamp": 1571258374102,
     "user": {
      "displayName": "Mihail Burduja",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBsbb8Z2nES1p7u5hO8eYtUVNns_F_GTDUX-H11k-4=s64",
      "userId": "06467582067569643852"
     },
     "user_tz": -180
    },
    "id": "m4_kNIIZXhPN",
    "outputId": "bdf8a2c0-88fb-4d08-8969-3f0a4c9987f6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 784)\n"
     ]
    }
   ],
   "source": [
    "train_images = np.load('data/train_images.npy') # load training images\n",
    "train_labels = np.load('data/train_labels.npy') # load training labels\n",
    "image = train_images[0, :] # the first image\n",
    "image = np.reshape(image, (28, 28)) \n",
    "plt.imshow(np.uint8(image))\n",
    "plt.show()\n",
    "print(train_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uDQfxC7FXhPP"
   },
   "source": [
    "## k-Nearest Neighbor\n",
    "\n",
    "The **nearest neighbor** method takes a **test** example, compare it to every single **training** example, and predict the label of the **closest** training example.\n",
    "\n",
    "In order to find the closest example(s), we have to define (or choose) a **metric**.\n",
    "\n",
    "Instead of using the closest example in the training set, we can find the top **k** closest examples and predict their majority label (*classification*) or the mean of their labels (*regression*). This strategy is called **k-NN**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vkSnVUJyXhPQ"
   },
   "source": [
    "![knn.jpeg](attachment:knn.jpeg)\n",
    "\n",
    "An example of the difference between Nearest Neighbor and a 5-Nearest Neighbor classifier, using 2-dimensional points and 3 classes (red, blue, green). The colored regions show the decision boundaries induced by the classifier with an L2 distance. The white regions show points that are ambiguously classified (i.e. class votes are tied for at least two classes). Notice that in the case of a NN classifier, outlier datapoints (e.g. green point in the middle of a cloud of blue points) create small islands of likely incorrect predictions, while the 5-NN classifier smooths over these irregularities, likely leading to better generalization on the test data (not shown). Also note that the gray regions in the 5-NN image are caused by ties in the votes among the nearest neighbors (e.g. 2 neighbors are red, next two neighbors are blue, last neighbor is green)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_JVqo1ZtXhPR"
   },
   "source": [
    "The most common distances are:\n",
    "    $$L_1(X, Y) = \\sum_i{\\mid X_i - Y_i \\mid}$$\n",
    "    $$L_2(X, Y) = \\sqrt{\\sum_i{(X_i - Y_i) ^ 2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fMU4FdUuXhPR"
   },
   "source": [
    "# Execises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wdBi6Z60XhPS"
   },
   "source": [
    "#### 1. Create the 'Knn_classifier' class in order to classify the MNIST testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eHiBQbFZXhPT"
   },
   "outputs": [],
   "source": [
    "class Knn_classifier:\n",
    "    \n",
    "    def __init__(self, train_images, train_labels):\n",
    "        self.train_images = train_images\n",
    "        self.train_labels = train_labels\n",
    "    \n",
    "    # a. Write the classify_image(self, test_image, num_neighbors=3, metric='l2') function in order to classify 'test_image'\n",
    "    # example using the k-NN method with 'num_neighbors' neighbors and 'metric' distance.\n",
    "    def classify_image(self, test_image, num_neighbors=3, metric='l2'):\n",
    "        # write your code here\n",
    "        compute the distance between the test image and each train image\n",
    "        get the closest num_neighbors neighbors\n",
    "        get their labels\n",
    "        return the label with the highest count from the neighbors\n",
    "    \n",
    "    # b. Write the classify_images(self, test_images, num_neighbors=3, metric='l2') function in order to predict the labels of \n",
    "    # the test images.\n",
    "    def classify_images(self):\n",
    "        # write your code here\n",
    "        pass\n",
    "    \n",
    "    # c. Define a function to compute the accurracy score given the predicted labels and the ground-truth labels.\n",
    "    def accuracy_score(self):\n",
    "        # write your code here\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n4VO2ToFXhPV"
   },
   "source": [
    "#### 2. Compute the accuracy score of the 3-NN method on the test set using L_2 distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRBYUTMnXhPV"
   },
   "outputs": [],
   "source": [
    "train_images = np.load('data/train_images.npy') # load training images\n",
    "train_labels = np.load('data/train_labels.npy') # load training labels\n",
    "test_images = np.load('data/test_images.npy') # load testing images\n",
    "test_labels = np.load('data/test_labels.npy') # load testing labels\n",
    "\n",
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLoU_VrgXhPY"
   },
   "source": [
    "#### 3. Compute the confusion matrix of the previous classifier.\n",
    "\n",
    "Confusion matrix: $$C = c_{i, j}$$ number of examples in class __i that were classified as j__.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hr2Uek3lXhPY"
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g5Be4imeXhPb"
   },
   "source": [
    "#### 4. Plot the accuracy score of the k-NN method with  $k \\in \\{1, 3, 5, 7, 9\\}$ and distance $L_2.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jkh53rY_XhPb"
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wsLAni9iXhPd"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab2-knn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
